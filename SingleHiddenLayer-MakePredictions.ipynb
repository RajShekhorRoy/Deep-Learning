{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajdiahmed/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)  \n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)  \n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print (train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajdiahmed/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajdiahmed/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06896552]\n",
      " [0.87356322]\n",
      " [0.5862069 ]\n",
      " ...\n",
      " [0.70114943]\n",
      " [0.32183908]\n",
      " [0.8045977 ]]\n"
     ]
    }
   ],
   "source": [
    "print (scaled_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 420 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 0.6445 - acc: 0.5754 - val_loss: 0.6217 - val_acc: 0.6262\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6088 - acc: 0.6844 - val_loss: 0.5778 - val_acc: 0.7167\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.5631 - acc: 0.7534 - val_loss: 0.5211 - val_acc: 0.8095\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5129 - acc: 0.8082 - val_loss: 0.4620 - val_acc: 0.8714\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.4628 - acc: 0.8484 - val_loss: 0.4044 - val_acc: 0.9095\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.4189 - acc: 0.8749 - val_loss: 0.3541 - val_acc: 0.9143\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.3834 - acc: 0.8902 - val_loss: 0.3129 - val_acc: 0.9452\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.3559 - acc: 0.8979 - val_loss: 0.2804 - val_acc: 0.9667\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3353 - acc: 0.9108 - val_loss: 0.2532 - val_acc: 0.9667\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.3197 - acc: 0.9159 - val_loss: 0.2318 - val_acc: 0.9857\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.3082 - acc: 0.9225 - val_loss: 0.2148 - val_acc: 0.9857\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2997 - acc: 0.9243 - val_loss: 0.2012 - val_acc: 0.9881\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2930 - acc: 0.9315 - val_loss: 0.1891 - val_acc: 0.9857\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2882 - acc: 0.9288 - val_loss: 0.1810 - val_acc: 0.9881\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2842 - acc: 0.9310 - val_loss: 0.1730 - val_acc: 0.9881\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2809 - acc: 0.9333 - val_loss: 0.1672 - val_acc: 0.9952\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2781 - acc: 0.9341 - val_loss: 0.1612 - val_acc: 0.9952\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2757 - acc: 0.9357 - val_loss: 0.1564 - val_acc: 0.9881\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2734 - acc: 0.9357 - val_loss: 0.1517 - val_acc: 0.9881\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2715 - acc: 0.9354 - val_loss: 0.1488 - val_acc: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a151a5240>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20,shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95645076 0.04354925]\n",
      "[0.32688725 0.67311275]\n",
      "[0.95645076 0.04354925]\n",
      "[0.16790569 0.8320943 ]\n",
      "[0.57501006 0.42498988]\n",
      "[0.01723795 0.98276204]\n",
      "[0.95645076 0.04354925]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.04258926 0.95741075]\n",
      "[0.95645076 0.04354925]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.67731184 0.32268813]\n",
      "[0.29553065 0.7044694 ]\n",
      "[0.57501006 0.42498988]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.8347525  0.16524749]\n",
      "[0.0240132  0.97598684]\n",
      "[0.8996729 0.1003271]\n",
      "[0.04258926 0.95741075]\n",
      "[0.9418919  0.05810806]\n",
      "[0.06358867 0.9364114 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05873318 0.9412669 ]\n",
      "[0.6103294 0.3896706]\n",
      "[0.01873127 0.9812687 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.87129295 0.12870707]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02607789 0.9739221 ]\n",
      "[0.93087894 0.06912106]\n",
      "[0.29553065 0.7044694 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.95480597 0.04519407]\n",
      "[0.05873318 0.9412669 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.04258926 0.95741075]\n",
      "[0.95645076 0.04354925]\n",
      "[0.3598713  0.64012873]\n",
      "[0.87129295 0.12870707]\n",
      "[0.05004812 0.9499519 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.03926999 0.96072996]\n",
      "[0.85396767 0.14603235]\n",
      "[0.03926999 0.96072996]\n",
      "[0.57501006 0.42498988]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.85396767 0.14603235]\n",
      "[0.29553065 0.7044694 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.9418919  0.05810806]\n",
      "[0.06358867 0.9364114 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05004814 0.9499519 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.01873127 0.9812687 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.03927    0.96072996]\n",
      "[0.95480597 0.04519407]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.67731184 0.32268813]\n",
      "[0.18936074 0.81063926]\n",
      "[0.8347525  0.16524749]\n",
      "[0.03926999 0.96072996]\n",
      "[0.8347525  0.16524749]\n",
      "[0.39423403 0.605766  ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.95028806 0.04971197]\n",
      "[0.13086961 0.8691304 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.03619966 0.9638004 ]\n",
      "[0.94518197 0.05481803]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.13086961 0.8691304 ]\n",
      "[0.8347525  0.16524749]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.70843995 0.29156002]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.5023935  0.49760652]\n",
      "[0.04258926 0.95741075]\n",
      "[0.93474936 0.06525069]\n",
      "[0.07443932 0.92556065]\n",
      "[0.9418919  0.05810806]\n",
      "[0.09000713 0.9099929 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.13086964 0.8691304 ]\n",
      "[0.95220697 0.04779309]\n",
      "[0.05004814 0.9499519 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.09000713 0.9099929 ]\n",
      "[0.92247045 0.07752953]\n",
      "[0.32688725 0.67311275]\n",
      "[0.95645076 0.04354925]\n",
      "[0.01723795 0.98276204]\n",
      "[0.95645076 0.04354924]\n",
      "[0.09000713 0.9099929 ]\n",
      "[0.85396767 0.14603235]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.32688725 0.67311275]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.87129295 0.12870705]\n",
      "[0.39423403 0.605766  ]\n",
      "[0.70843995 0.29156002]\n",
      "[0.16790569 0.8320943 ]\n",
      "[0.813561   0.18643902]\n",
      "[0.07443932 0.92556065]\n",
      "[0.9557737 0.0442263]\n",
      "[0.08115327 0.9188468 ]\n",
      "[0.8868351  0.11316483]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.18936074 0.81063926]\n",
      "[0.92247045 0.07752953]\n",
      "[0.05004812 0.9499519 ]\n",
      "[0.93474936 0.06525069]\n",
      "[0.0240132  0.97598684]\n",
      "[0.9167971  0.08320291]\n",
      "[0.16790569 0.8320943 ]\n",
      "[0.953818   0.04618198]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.926797   0.07320305]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.926797   0.07320305]\n",
      "[0.02831496 0.971685  ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.29553065 0.7044694 ]\n",
      "[0.94829595 0.05170406]\n",
      "[0.3598713  0.64012873]\n",
      "[0.95480597 0.04519407]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.07443932 0.92556065]\n",
      "[0.95645076 0.04354924]\n",
      "[0.05422697 0.94577307]\n",
      "[0.95028806 0.04971197]\n",
      "[0.05422698 0.94577307]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.8996729 0.1003271]\n",
      "[0.06881618 0.9311839 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.04617558 0.9538244 ]\n",
      "[0.93087894 0.06912106]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.8347525  0.16524749]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.13086961 0.8691304 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05004814 0.9499519 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.06358867 0.9364114 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.13086961 0.8691304 ]\n",
      "[0.813561   0.18643902]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.67731184 0.32268813]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.9167971  0.08320291]\n",
      "[0.23840924 0.7615907 ]\n",
      "[0.9093271  0.09067287]\n",
      "[0.23840924 0.7615908 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02607789 0.9739221 ]\n",
      "[0.57501006 0.42498988]\n",
      "[0.02035128 0.97964877]\n",
      "[0.95028806 0.04971197]\n",
      "[0.03926999 0.96072996]\n",
      "[0.95645076 0.04354925]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.6445278  0.35547224]\n",
      "[0.11510073 0.88489926]\n",
      "[0.70843995 0.29156002]\n",
      "[0.06358867 0.9364114 ]\n",
      "[0.926797   0.07320305]\n",
      "[0.03073789 0.9692621 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.07443932 0.92556065]\n",
      "[0.95480597 0.04519407]\n",
      "[0.03336102 0.966639  ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.09000713 0.9099929 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.04617558 0.9538244 ]\n",
      "[0.94829595 0.05170406]\n",
      "[0.03336102 0.966639  ]\n",
      "[0.813561   0.18643902]\n",
      "[0.04617558 0.9538244 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.9167971  0.08320291]\n",
      "[0.3598712  0.64012873]\n",
      "[0.95645076 0.04354925]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.32688725 0.67311275]\n",
      "[0.95480597 0.04519407]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.94518197 0.05481803]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.02210825 0.9778918 ]\n",
      "[0.76504993 0.2349501 ]\n",
      "[0.03619966 0.9638004 ]\n",
      "[0.8868351  0.11316483]\n",
      "[0.03336102 0.966639  ]\n",
      "[0.9167971  0.08320291]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.926797   0.07320305]\n",
      "[0.01723795 0.98276204]\n",
      "[0.95645076 0.04354925]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.5023935  0.49760652]\n",
      "[0.06358867 0.9364114 ]\n",
      "[0.7377282  0.26227182]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.70843995 0.29156002]\n",
      "[0.01723795 0.98276204]\n",
      "[0.95645076 0.04354925]\n",
      "[0.03336102 0.966639  ]\n",
      "[0.6103294 0.3896706]\n",
      "[0.23840924 0.7615907 ]\n",
      "[0.57501006 0.42498988]\n",
      "[0.0240132  0.97598684]\n",
      "[0.92247045 0.07752953]\n",
      "[0.06881618 0.9311839 ]\n",
      "[0.95028806 0.04971197]\n",
      "[0.13086964 0.8691304 ]\n",
      "[0.92247045 0.07752953]\n",
      "[0.02831496 0.971685  ]\n",
      "[0.93087894 0.06912108]\n",
      "[0.05873318 0.9412669 ]\n",
      "[0.9418919  0.05810806]\n",
      "[0.02607789 0.9739221 ]\n",
      "[0.76504993 0.2349501 ]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.03619966 0.9638004 ]\n",
      "[0.93087894 0.06912108]\n",
      "[0.03619966 0.9638004 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.07443932 0.92556065]\n",
      "[0.5389081 0.4610919]\n",
      "[0.02035128 0.97964877]\n",
      "[0.92247045 0.07752953]\n",
      "[0.3598713  0.64012873]\n",
      "[0.9093271  0.09067287]\n",
      "[0.01873127 0.9812687 ]\n",
      "[0.85396767 0.14603235]\n",
      "[0.01723795 0.98276204]\n",
      "[0.95645076 0.04354925]\n",
      "[0.18936074 0.81063926]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05422698 0.94577307]\n",
      "[0.95645076 0.04354925]\n",
      "[0.39423403 0.605766  ]\n",
      "[0.85396767 0.14603235]\n",
      "[0.1484364 0.8515636]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.953818   0.04618198]\n",
      "[0.01723795 0.98276204]\n",
      "[0.94518197 0.05481803]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.94829595 0.05170406]\n",
      "[0.05422698 0.94577307]\n",
      "[0.6103294 0.3896706]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.92247045 0.07752953]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.9418919  0.05810806]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.94829595 0.05170406]\n",
      "[0.0240132  0.97598684]\n",
      "[0.95480597 0.04519407]\n",
      "[0.06881618 0.9311839 ]\n",
      "[0.7377282  0.26227182]\n",
      "[0.08115327 0.9188468 ]\n",
      "[0.95028806 0.04971197]\n",
      "[0.07443932 0.92556065]\n",
      "[0.85396767 0.14603235]\n",
      "[0.03926999 0.96072996]\n",
      "[0.87129295 0.12870707]\n",
      "[0.05422697 0.94577307]\n",
      "[0.4658531  0.53414696]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.03336102 0.966639  ]\n",
      "[0.9557737 0.0442263]\n",
      "[0.05422698 0.94577307]\n",
      "[0.95645076 0.04354925]\n",
      "[0.13086961 0.8691304 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.03073789 0.9692621 ]\n",
      "[0.9167971  0.08320291]\n",
      "[0.03926999 0.96072996]\n",
      "[0.95645076 0.04354925]\n",
      "[0.07443932 0.92556065]\n",
      "[0.92247045 0.07752953]\n",
      "[0.32688725 0.67311275]\n",
      "[0.6445278  0.35547218]\n",
      "[0.11510073 0.88489926]\n",
      "[0.953818   0.04618197]\n",
      "[0.32688725 0.67311275]\n",
      "[0.95480597 0.04519407]\n",
      "[0.01586174 0.9841383 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.11510073 0.88489926]\n",
      "[0.95645076 0.04354925]\n",
      "[0.23840924 0.7615907 ]\n",
      "[0.9418919  0.05810806]\n",
      "[0.26599345 0.7340065 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.04617558 0.9538244 ]\n",
      "[0.76504993 0.2349501 ]\n",
      "[0.39423403 0.605766  ]\n",
      "[0.93474936 0.06525069]\n",
      "[0.04258926 0.95741075]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05004814 0.9499519 ]\n",
      "[0.6445278  0.35547218]\n",
      "[0.05873318 0.9412669 ]\n",
      "[0.926797   0.07320305]\n",
      "[0.32688725 0.67311275]\n",
      "[0.95645076 0.04354925]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.9093271  0.09067287]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.11510073 0.88489926]\n",
      "[0.95645076 0.04354925]\n",
      "[0.18936074 0.81063926]\n",
      "[0.92247045 0.07752953]\n",
      "[0.01723795 0.98276204]\n",
      "[0.93087894 0.06912108]\n",
      "[0.29553065 0.7044694 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.23840924 0.7615907 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.4658531  0.53414696]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.9384173 0.0615827]\n",
      "[0.05422697 0.94577307]\n",
      "[0.8996729 0.1003271]\n",
      "[0.0240132  0.97598684]\n",
      "[0.94518197 0.05481803]\n",
      "[0.04617558 0.9538244 ]\n",
      "[0.5389081 0.4610919]\n",
      "[0.09000713 0.9099929 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02035128 0.97964877]\n",
      "[0.95645076 0.04354924]\n",
      "[0.08115327 0.9188468 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.02607789 0.9739221 ]\n",
      "[0.6103294 0.3896706]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.9384173 0.0615827]\n",
      "[0.08115327 0.9188468 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.11510073 0.88489926]\n",
      "[0.67731184 0.32268813]\n",
      "[0.3598713  0.64012873]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05004814 0.9499519 ]\n",
      "[0.95645076 0.04354925]\n",
      "[0.42967564 0.5703243 ]\n",
      "[0.95220697 0.04779309]\n",
      "[0.05004814 0.9499519 ]\n",
      "[0.95645076 0.04354924]\n",
      "[0.01873127 0.9812687 ]\n",
      "[0.8347525  0.16524749]\n",
      "[0.02210826 0.9778918 ]\n",
      "[0.67731184 0.32268813]\n",
      "[0.14843638 0.8515636 ]\n",
      "[0.9384173 0.0615827]\n",
      "[0.01723795 0.98276204]\n",
      "[0.76504993 0.2349501 ]\n",
      "[0.13086961 0.8691304 ]\n",
      "[0.926797   0.07320305]\n",
      "[0.05873319 0.9412668 ]\n",
      "[0.9557737 0.0442263]\n",
      "[0.10123899 0.898761  ]\n",
      "[0.92247045 0.07752953]\n",
      "[0.21285613 0.7871439 ]\n",
      "[0.67731184 0.32268813]\n",
      "[0.01723795 0.98276204]\n",
      "[0.95645076 0.04354925]\n",
      "[0.05422698 0.94577307]\n",
      "[0.93474936 0.06525069]\n",
      "[0.18936075 0.81063926]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
