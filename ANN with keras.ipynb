{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 73, 35, 70, 13, 70, 27, 74, 54, 66, 61, 97, 60, 79, 29, 92, 44, 75, 54, 73, 59, 68, 44, 70, 37, 93, 45, 81, 16, 89, 63, 96, 14, 79, 63, 90, 54, 93, 27, 93, 35, 90, 47, 67, 47, 95, 37, 90, 59, 67, 34, 68, 63, 74, 27, 68, 61, 87, 41, 96, 25, 86, 56, 86, 24, 75, 52, 75, 46, 79, 60, 72, 48, 80, 44, 88, 25, 78, 53, 94, 29, 100, 52, 82, 19, 94, 52, 72, 49, 97, 14, 69, 29, 65, 55, 99, 44, 77, 26, 100, 32, 85, 26, 73, 14, 73, 42, 69, 17, 90, 58, 75, 59, 72, 21, 94, 45, 81, 43, 76, 16, 65, 49, 89, 59, 100, 34, 91, 37, 81, 38, 87, 21, 87, 33, 84, 49, 95, 24, 99, 19, 92, 31, 72, 25, 78, 63, 86, 41, 94, 29, 79, 37, 72, 25, 84, 26, 82, 24, 74, 63, 91, 22, 66, 31, 86, 63, 79, 60, 74, 22, 94, 52, 75, 45, 88, 42, 72, 38, 89, 17, 74, 17, 76, 35, 81, 14, 78, 32, 99, 64, 83, 46, 75, 60, 67, 48, 66, 51, 85, 20, 68, 22, 87, 59, 67, 21, 88, 39, 98, 20, 77, 46, 75, 30, 92, 13, 94, 52, 92, 30, 86, 50, 84, 36, 81, 40, 96, 21, 68, 25, 75, 57, 90, 23, 78, 28, 75, 37, 66, 33, 85, 45, 74, 55, 92, 38, 87, 29, 89, 57, 77, 45, 71, 41, 93, 14, 70, 45, 77, 19, 75, 55, 95, 58, 70, 22, 88, 55, 87, 31, 84, 52, 93, 46, 92, 27, 69, 63, 78, 28, 85, 24, 80, 58, 77, 43, 97, 35, 65, 19, 80, 32, 96, 50, 85, 21, 76, 51, 82, 48, 92, 58, 67, 59, 70, 42, 66, 29, 83, 63, 69, 44, 73, 13, 93, 56, 97, 22, 70, 52, 94, 31, 89, 40, 83, 40, 97, 15, 85, 14, 87, 15, 72, 40, 99, 45, 93, 61, 93, 17, 65, 33, 84, 63, 74, 34, 74, 57, 94, 14, 86, 61, 97, 45, 100, 21, 78, 37, 79, 48, 99, 24, 86, 53, 100, 19, 73, 39, 76, 31, 75, 42, 84, 16, 85, 31, 75, 31, 91, 33, 91, 53, 86, 33, 68, 19, 87, 61, 82, 27, 78, 34, 89, 40, 93, 46, 84, 29, 69, 63, 75, 60, 100, 57, 81, 13, 88, 62, 84, 27, 98, 20, 72, 45, 91, 14, 86, 47, 71, 58, 86, 42, 98, 61, 96, 35, 99, 28, 100, 23, 75, 59, 94, 40, 68, 50, 75, 60, 89, 53, 84, 55, 71, 36, 84, 34, 70, 26, 91, 43, 91, 62, 94, 61, 71, 22, 99, 42, 71, 15, 83, 28, 100, 63, 76, 55, 76, 64, 92, 26, 83, 40, 85, 54, 91, 17, 94, 20, 96, 22, 87, 42, 90, 23, 65, 37, 91, 25, 65, 41, 65, 54, 80, 44, 97, 55, 91, 54, 92, 54, 84, 18, 66, 40, 86, 52, 87, 52, 83, 34, 66, 32, 72, 49, 91, 24, 74, 34, 77, 61, 72, 35, 93, 58, 98, 20, 77, 49, 68, 50, 97, 53, 98, 47, 76, 24, 86, 57, 70, 18, 82, 38, 90, 25, 91, 18, 74, 22, 80, 46, 80, 22, 84, 51, 83, 54, 96, 50, 81, 28, 73, 55, 75, 50, 85, 16, 82, 42, 79, 38, 70, 63, 73, 24, 70, 18, 82, 25, 76, 42, 66, 15, 85, 58, 71, 55, 97, 51, 71, 15, 69, 28, 85, 16, 96, 47, 93, 60, 78, 20, 72, 43, 66, 42, 66, 59, 84, 40, 69, 23, 78, 37, 75, 55, 76, 30, 89, 50, 76, 48, 95, 55, 98, 39, 72, 32, 66, 60, 77, 30, 86, 28, 86, 47, 73, 21, 98, 47, 76, 35, 65, 15, 75, 59, 85, 18, 85, 15, 91, 30, 74, 23, 83, 14, 84, 57, 83, 17, 93, 16, 74, 33, 82, 35, 78, 16, 85, 54, 100, 26, 86, 17, 73, 21, 91, 32, 100, 39, 77, 48, 67, 48, 75, 64, 100, 61, 75, 23, 74, 43, 86, 46, 90, 14, 87, 31, 88, 28, 80, 18, 78, 28, 89, 29, 70, 26, 78, 29, 88, 26, 87, 60, 86, 17, 73, 39, 66, 16, 74, 42, 98, 17, 99, 20, 85, 64, 79, 23, 79, 52, 85, 33, 95, 59, 72, 47, 76, 26, 100, 35, 97, 63, 92, 15, 89, 58, 90, 42, 71, 61, 98, 23, 69, 62, 69, 51, 74, 36, 67, 42, 88, 32, 88, 40, 88, 57, 97, 26, 84, 59, 86, 14, 90, 23, 98, 24, 100, 51, 86, 56, 66, 30, 100, 52, 74, 55, 66, 30, 73, 45, 98, 30, 86, 56, 65, 17, 71, 28, 93, 33, 75, 36, 85, 46, 87, 23, 96, 37, 99, 23, 100, 46, 80, 36, 66, 23, 81, 40, 74, 38, 73, 29, 81, 50, 91, 18, 92, 45, 65, 30, 87, 61, 89, 17, 90, 44, 68, 26, 69, 32, 75, 55, 85, 61, 66, 42, 69, 43, 93, 15, 93, 54, 76, 60, 91, 43, 88, 20, 78, 23, 77, 35, 98, 40, 85, 26, 77, 46, 75, 56, 83, 14, 75, 61, 68, 60, 69, 52, 68, 58, 100, 54, 91, 47, 67, 23, 85, 16, 68, 47, 89, 22, 73, 55, 89, 23, 97, 26, 83, 59, 97, 39, 74, 37, 67, 51, 98, 29, 78, 19, 79, 59, 76, 57, 82, 57, 94, 38, 85, 19, 97, 38, 75, 17, 86, 57, 70, 41, 69, 43, 99, 34, 67, 17, 65, 25, 97, 37, 77, 54, 74, 18, 99, 27, 82, 25, 92, 34, 87, 61, 90, 27, 71, 53, 87, 51, 90, 46, 84, 50, 84, 13, 93, 22, 83, 63, 98, 36, 100, 55, 87, 22, 86, 42, 94, 57, 88, 30, 82, 57, 76, 18, 71, 59, 68, 49, 72, 44, 66, 16, 75, 57, 94, 57, 96, 55, 91, 53, 88, 60, 99, 60, 97, 20, 91, 42, 72, 34, 84, 64, 78, 26, 66, 46, 83, 14, 100, 17, 77, 21, 72, 43, 74, 15, 96, 27, 77, 45, 93, 48, 67, 39, 67, 62, 98, 30, 85, 26, 68, 26, 68, 21, 97, 44, 86, 44, 96, 24, 96, 43, 85, 38, 90, 52, 97, 13, 97, 28, 73, 14, 65, 40, 67, 50, 87, 26, 77, 54, 71, 57, 84, 14, 93, 43, 76, 59, 87, 13, 84, 24, 83, 45, 77, 21, 65, 39, 76, 23, 79, 20, 80, 22, 95, 31, 68, 13, 100, 62, 76, 17, 74, 16, 88, 53, 74, 59, 66, 23, 78, 30, 94, 43, 86, 32, 81, 34, 97, 24, 71, 62, 90, 46, 77, 60, 84, 43, 85, 51, 82, 35, 96, 59, 87, 49, 78, 17, 94, 26, 97, 40, 80, 51, 82, 44, 76, 15, 89, 39, 87, 53, 87, 55, 71, 35, 94, 49, 67, 48, 70, 58, 90, 52, 90, 34, 82, 30, 79, 64, 83, 24, 74, 58, 91, 19, 83, 46, 69, 62, 75, 31, 73, 17, 74, 15, 68, 57, 96, 48, 100, 32, 73, 51, 79, 37, 98, 43, 97, 58, 81, 49, 65, 13, 84, 58, 76, 62, 68, 19, 91, 56, 91, 35, 65, 42, 98, 45, 81, 24, 94, 50, 81, 22, 78, 56, 66, 46, 70, 30, 69, 42, 72, 51, 87, 34, 70, 31, 77, 52, 99, 26, 71, 34, 95, 14, 91, 30, 74, 56, 87, 51, 88, 36, 85, 27, 95, 48, 90, 60, 89, 42, 69, 57, 91, 30, 71, 24, 80, 21, 97, 22, 99, 34, 77, 58, 93, 39, 98, 38, 80, 53, 90, 40, 80, 27, 75, 58, 76, 31, 83, 31, 82, 41, 91, 35, 99, 56, 92, 25, 93, 59, 91, 20, 70, 37, 81, 37, 87, 41, 78, 55, 69, 38, 94, 59, 75, 54, 68, 38, 100, 49, 95, 35, 85, 28, 65, 39, 79, 30, 74, 59, 99, 23, 71, 15, 72, 33, 100, 32, 84, 53, 97, 25, 79, 22, 73, 38, 81, 16, 74, 38, 74, 57, 88, 15, 96, 36, 81, 43, 65, 32, 86, 59, 68, 50, 80, 61, 95, 55, 91, 39, 99, 46, 94, 26, 70, 20, 81, 34, 97, 26, 71, 46, 98, 36, 97, 14, 96, 63, 72, 22, 67, 22, 69, 17, 99, 55, 99, 33, 79, 22, 71, 39, 77, 64, 69, 26, 99, 57, 67, 36, 80, 44, 79, 22, 92, 22, 80, 31, 67, 61, 92, 44, 79, 44, 85, 33, 75, 59, 69, 49, 84, 41, 87, 52, 73, 17, 94, 43, 74, 25, 66, 42, 77, 17, 68, 33, 85, 18, 74, 55, 89, 58, 73, 46, 91, 54, 76, 16, 82, 23, 100, 29, 83, 14, 83, 30, 88, 28, 83, 40, 72, 26, 93, 32, 81, 57, 91, 52, 73, 28, 88, 29, 87, 44, 97, 63, 81, 32, 72, 56, 73, 51, 66, 55, 83, 43, 81, 32, 90, 13, 72, 22, 94, 19, 68, 29, 66, 23, 95, 17, 83, 63, 69, 62, 79, 22, 68, 25, 67, 57, 86, 31, 74, 25, 67, 63, 71, 62, 90, 45, 68, 15, 98, 19, 99, 18, 73, 30, 98, 55, 92, 62, 94, 42, 65, 39, 89, 18, 65, 40, 94, 16, 91, 50, 65, 48, 83, 61, 89, 52, 96, 52, 81, 56, 83, 56, 99, 44, 69, 58, 100, 13, 84, 29, 93, 42, 71, 37, 98, 52, 96, 56, 87, 38, 95, 43, 82, 54, 81, 17, 65, 49, 92, 24, 89, 43, 99, 35, 79, 56, 87, 26, 84, 18, 97, 50, 91, 35, 80, 22, 74, 32, 69, 63, 94, 63, 89, 24, 94, 63, 72, 32, 69, 50, 89, 34, 74, 56, 79, 39, 71, 16, 74, 48, 91, 35, 97, 37, 77, 22, 82, 59, 65, 43, 95, 15, 89, 47, 91, 15, 70, 26, 79, 56, 85, 24, 70, 24, 82, 20, 66, 40, 66, 33, 77, 36, 78, 61, 85, 42, 85, 53, 70, 63, 89, 44, 87, 24, 65, 44, 89, 22, 88, 36, 92, 45, 74, 20, 89, 52, 91, 53, 97, 39, 91, 18, 74, 52, 76, 33, 76, 64, 89, 50, 90, 16, 66, 52, 98, 49, 79, 57, 94, 63, 93, 52, 84, 13, 94, 56, 82, 30, 95, 20, 89, 54, 90, 17, 78, 21, 66, 24, 83, 30, 98, 56, 86, 39, 70, 27, 74, 30, 100, 46, 71, 50, 89, 25, 83, 39, 79, 53, 73, 47, 80, 56, 97, 16, 86, 63, 67, 13, 81, 59, 97, 22, 81, 32, 88, 36, 98, 22, 97, 51, 66, 36, 89, 14, 86, 54, 93, 57, 91, 48, 76, 52, 98, 56, 65, 47, 93, 38, 86, 59, 73, 33, 97, 45, 94, 55, 80, 28, 94, 29, 65, 56, 95, 26, 97, 39, 93, 34, 82, 18, 70, 60, 77, 47, 70, 53, 84, 29, 84, 13, 81, 39, 85, 27, 80, 15, 96, 57, 85, 29, 92, 19, 73, 41, 75, 62, 75, 44, 94, 22, 78, 40, 92, 59, 70, 64, 97, 46, 75, 55, 90, 51, 89, 30, 100, 47, 84, 31, 69, 31, 100, 53, 74, 41, 70, 32, 84, 54, 69, 52, 66, 43, 74, 24, 76, 64, 93, 57, 82, 49, 72, 18, 67, 48, 96, 39, 81, 55, 99, 23, 65, 22, 98, 45, 90, 33, 71, 18, 89, 59, 80, 44, 66, 64, 94, 57, 80, 27, 89, 52, 65, 51, 78, 39, 73, 42, 93, 43, 74, 59, 71, 63, 81, 58, 99, 20, 91, 29, 92, 34, 97, 55, 72, 51, 76, 23, 78, 14, 99, 18, 100, 64, 71, 20, 99, 16, 92, 46, 86, 17, 68, 18, 71, 56, 68, 61, 83, 46, 96, 46, 91, 53, 65, 14, 85, 52, 78, 47, 89, 55, 86, 53, 66, 35, 91, 46, 96, 37, 86, 17, 80, 18, 100, 30, 77, 32, 85, 51, 100, 46, 69, 31, 83, 17, 97, 30, 89, 33, 83, 28, 70, 56, 91, 17, 82, 50, 88, 27, 81, 26, 99, 41, 82, 41, 90, 48, 95, 46, 84, 42, 84, 20, 77, 39, 73, 63, 99, 26, 87, 33, 77, 13, 96, 30, 91, 17, 70, 59, 99, 35, 85, 15, 68, 24, 73, 24, 86, 22, 78, 39, 67, 13, 86, 38, 77, 56, 80, 57, 88, 63, 69, 52, 74, 19, 78, 42, 83, 54, 68, 54, 99, 25, 85, 53, 77, 30, 89, 58, 90, 57, 70, 58, 88, 51, 93, 15, 97, 55, 77, 39, 76, 56, 66, 57, 88]\n"
     ]
    }
   ],
   "source": [
    "print (train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajdiahmed/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22988506]\n",
      " [ 0.68965517]\n",
      " [ 0.25287356]\n",
      " ..., \n",
      " [ 0.6091954 ]\n",
      " [ 0.50574713]\n",
      " [ 0.86206897]]\n"
     ]
    }
   ],
   "source": [
    "print (scaled_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.6931 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a14cc6080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20,shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
