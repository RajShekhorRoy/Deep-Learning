{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajdiahmed/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/wajdiahmed/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/divamgupta/image-segmentation-keras\n",
    "#Divam Gupta\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "import os\n",
    "#file_path = os.path.dirname( os.path.abspath(__file__) )\n",
    "\n",
    "\n",
    "VGG_Weights_path = \"/Users/wajdiahmed/Kaggle/vgg16_weights_th_dim_ordering_th_kernels.h5\"\n",
    "\n",
    "IMAGE_ORDERING = 'channels_first'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def VGGUnet( n_classes ,  input_height=416, input_width=608 , vgg_level=3):\n",
    "\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "\n",
    "    # https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5\n",
    "    img_input = Input(shape=(3,input_height,input_width))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f4 = x\n",
    "\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f5 = x\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense( 1000 , activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg  = Model(  img_input , x  )\n",
    "    vgg.load_weights(VGG_Weights_path)\n",
    "\n",
    "    levels = [f1 , f2 , f3 , f4 , f5 ]\n",
    "\n",
    "    o = f4\n",
    "\n",
    "    o = ( ZeroPadding2D( (1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([ o ,f3],axis=1 )  )\n",
    "    o = ( ZeroPadding2D( (1,1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( Conv2D( 256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([o,f2],axis=1 ) )\n",
    "    o = ( ZeroPadding2D((1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 128 , (3, 3), padding='valid' , data_format=IMAGE_ORDERING ) )(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([o,f1],axis=1 ) )\n",
    "    o = ( ZeroPadding2D((1,1)  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "\n",
    "    o =  Conv2D( n_classes , (3, 3) , padding='same', data_format=IMAGE_ORDERING )( o )\n",
    "    o_shape = Model(img_input , o ).output_shape\n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "\n",
    "    o = (Reshape((  n_classes , outputHeight*outputWidth   )))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model( img_input , o )\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGUnet2( n_classes ,  input_height=416, input_width=608 , vgg_level=3):\n",
    "\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "\n",
    "    # https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5\n",
    "    img_input = Input(shape=(3,input_height,input_width))\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f4 = x\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense( 1024 , activation='softmax', name='predictions')(x)\n",
    "\n",
    "    vgg  = Model(  img_input , x  )\n",
    "    vgg.load_weights(VGG_Weights_path)\n",
    "\n",
    "    levels = [f1 , f2 , f3 , f4 , f5 ]\n",
    "\n",
    "    o = f4\n",
    "\n",
    "    o = ( ZeroPadding2D( (1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([ o ,f3],axis=1 )  )\n",
    "    o = ( ZeroPadding2D( (1,1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( Conv2D( 256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = ( concatenate([o,f2],axis=1 ) )\n",
    "    o = ( ZeroPadding2D((1,1) , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 128 , (3, 3), padding='valid' , data_format=IMAGE_ORDERING ) )(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
    "    # o = ( concatenate([o,f1],axis=1 ) )\n",
    "    o = ( ZeroPadding2D((1,1)  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format=IMAGE_ORDERING ))(o)\n",
    "    o = ( BatchNormalization())(o)\n",
    "\n",
    "\n",
    "    o =  Conv2D( n_classes , (3, 3) , padding='same', data_format=IMAGE_ORDERING )( o )\n",
    "    o_shape = Model(img_input , o ).output_shape\n",
    "    outputHeight = o_shape[2]\n",
    "    outputWidth = o_shape[3]\n",
    "\n",
    "    o = (Reshape((  n_classes , outputHeight*outputWidth   )))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    model = Model( img_input , o )\n",
    "    model.outputWidth = outputWidth\n",
    "    model.outputHeight = outputHeight\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "\n",
    "def getImageArr( path , width , height , imgNorm=\"sub_mean\" , odering='channels_first' ):\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(path, 1)\n",
    "\n",
    "        if imgNorm == \"sub_and_divide\":\n",
    "            img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
    "        elif imgNorm == \"sub_mean\":\n",
    "            img = cv2.resize(img, ( width , height ))\n",
    "            img = img.astype(np.float32)\n",
    "            img[:,:,0] -= 103.939\n",
    "            img[:,:,1] -= 116.779\n",
    "            img[:,:,2] -= 123.68\n",
    "        elif imgNorm == \"divide\":\n",
    "            img = cv2.resize(img, ( width , height ))\n",
    "            img = img.astype(np.float32)\n",
    "            img = img/255.0\n",
    "\n",
    "        if odering == 'channels_first':\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print (path , e)\n",
    "        img = np.zeros((  height , width  , 3 ))\n",
    "        if odering == 'channels_first':\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    try:\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = cv2.resize(img, ( width , height ))\n",
    "        img = img[:, : , 0]\n",
    "\n",
    "        for c in range(nClasses):\n",
    "            seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "\n",
    "    seg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
    "    return seg_labels\n",
    "\n",
    "\n",
    "\n",
    "def imageSegmentationGenerator( images_path , segs_path ,  batch_size,  n_classes , input_height , input_width , output_height , output_width   ):\n",
    "\n",
    "    assert images_path[-1] == '/'\n",
    "    assert segs_path[-1] == '/'\n",
    "\n",
    "    images = glob.glob( images_path + \"*.jpg\"  ) + glob.glob( images_path + \"*.png\"  ) +  glob.glob( images_path + \"*.jpeg\"  )\n",
    "    images.sort()\n",
    "    segmentations  = glob.glob( segs_path + \"*.jpg\"  ) + glob.glob( segs_path + \"*.png\"  ) +  glob.glob( segs_path + \"*.jpeg\"  )\n",
    "    segmentations.sort()\n",
    "\n",
    "    assert len( images ) == len(segmentations)\n",
    "    for im , seg in zip(images,segmentations):\n",
    "        assert(  im.split('/')[-1].split(\".\")[0] ==  seg.split('/')[-1].split(\".\")[0] )\n",
    "\n",
    "    zipped = itertools.cycle( zip(images,segmentations) )\n",
    "\n",
    "    while True:\n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range( batch_size) :\n",
    "            im , seg = zipped.next()\n",
    "            X.append( getImageArr(im , input_width , input_height )  )\n",
    "            Y.append( getSegmentationArr( seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "        yield np.array(X) , np.array(Y)\n",
    "\n",
    "\n",
    "# import Models , LoadBatches\n",
    "# G  = LoadBatches.imageSegmentationGenerator( \"data/clothes_seg/prepped/images_prepped_train/\" ,  \"data/clothes_seg/prepped/annotations_prepped_train/\" ,  1,  10 , 800 , 550 , 400 , 272   ) \n",
    "# G2  = LoadBatches.imageSegmentationGenerator( \"data/clothes_seg/prepped/images_prepped_test/\" ,  \"data/clothes_seg/prepped/annotations_prepped_test/\" ,  1,  10 , 800 , 550 , 400 , 272   ) \n",
    "\n",
    "# m = Models.VGGSegnet.VGGSegnet( 10  , use_vgg_weights=True ,  optimizer='adadelta' , input_image_size=( 800 , 550 )  )\n",
    "# m.fit_generator( G , 512  , nb_epoch=10 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the prepared data\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "def imageSegmentationGenerator( images_path , segs_path ,  n_classes ):\n",
    "\n",
    "    assert images_path[-1] == '/'\n",
    "    assert segs_path[-1] == '/'\n",
    "\n",
    "    images = glob.glob( images_path + \"*.jpg\"  ) + glob.glob( images_path + \"*.png\"  ) +  glob.glob( images_path + \"*.jpeg\"  )\n",
    "    images.sort()\n",
    "    segmentations  = glob.glob( segs_path + \"*.jpg\"  ) + glob.glob( segs_path + \"*.png\"  ) +  glob.glob( segs_path + \"*.jpeg\"  )\n",
    "    segmentations.sort()\n",
    "\n",
    "    colors = [  ( random.randint(0,255),random.randint(0,255),random.randint(0,255)   ) for _ in range(n_classes)  ]\n",
    "\n",
    "    assert len( images ) == len(segmentations)\n",
    "\n",
    "    for im_fn, seg_fn in zip(images, segmentations):\n",
    "        assert(  im_fn.split('/')[-1] ==  seg_fn.split('/')[-1] )\n",
    "\n",
    "        img = cv2.imread( im_fn )\n",
    "        \n",
    "        seg = cv2.imread( seg_fn )\n",
    "        print (np.unique( seg ))\n",
    "\n",
    "        seg_img = np.zeros_like( seg )\n",
    "\n",
    "        for c in range(n_classes):\n",
    "            seg_img[:,:,0] += ((seg[:,:,0] == c )*( colors[c][0] )).astype('uint8')\n",
    "            seg_img[:,:,1] += ((seg[:,:,0] == c )*( colors[c][1] )).astype('uint8')\n",
    "            seg_img[:,:,2] += ((seg[:,:,0] == c )*( colors[c][2] )).astype('uint8')\n",
    "\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.imshow(seg_img)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images = \"/Users/wajdiahmed/Kaggle/Single_Cut/images/\" \n",
    "annotations = \"/Users/wajdiahmed/Kaggle/Single_Cut/masks/\"\n",
    "n_classes=2 \n",
    "\n",
    "imageSegmentationGenerator(images ,annotations  ,n_classes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 1024 and 1000. Shapes are [4096,1024] and [4096,1000]. for 'Assign_30' (op: 'Assign') with input shapes: [4096,1024], [4096,1000].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 1024 and 1000. Shapes are [4096,1024] and [4096,1000]. for 'Assign_30' (op: 'Assign') with input shapes: [4096,1024], [4096,1000].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6a8e0f3d920d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#modelFN = model_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGGUnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_height\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_width\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m m.compile(loss='categorical_crossentropy',\n\u001b[1;32m     55\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptimizer_name\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-aefad0be52d8>\u001b[0m in \u001b[0;36mVGGUnet2\u001b[0;34m(n_classes, input_height, input_width, vgg_level)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mvgg\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mimg_input\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVGG_Weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf5\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                 load_weights_from_hdf5_group(\n\u001b[0;32m-> 2667\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   3391\u001b[0m                              ' elements.')\n\u001b[1;32m   3392\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3393\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2371\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2372\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    643\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \"\"\"\n\u001b[0;32m--> 645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    214\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    215\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    217\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1731\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 1024 and 1000. Shapes are [4096,1024] and [4096,1000]. for 'Assign_30' (op: 'Assign') with input shapes: [4096,1024], [4096,1000]."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "\n",
    "\n",
    "#parser.add_argument(\"--save_weights_path\", type = str  )\n",
    "#parser.add_argument(\"--train_images\", type = str  )\n",
    "#parser.add_argument(\"--train_annotations\", type = str  )\n",
    "#parser.add_argument(\"--n_classes\", type=int )\n",
    "#parser.add_argument(\"--input_height\", type=int , default = 224  )\n",
    "#parser.add_argument(\"--input_width\", type=int , default = 224 )\n",
    "\n",
    "#parser.add_argument('--validate',action='store_false')\n",
    "#parser.add_argument(\"--val_images\", type = str , default = \"\")\n",
    "#parser.add_argument(\"--val_annotations\", type = str , default = \"\")\n",
    "\n",
    "#parser.add_argument(\"--epochs\", type = int, default = 5 )\n",
    "#parser.add_argument(\"--batch_size\", type = int, default = 2 )\n",
    "#parser.add_argument(\"--val_batch_size\", type = int, default = 2 )\n",
    "#parser.add_argument(\"--load_weights\", type = str , default = \"\")\n",
    "\n",
    "#parser.add_argument(\"--model_name\", type = str , default = \"\")\n",
    "#parser.add_argument(\"--optimizer_name\", type = str , default = \"adadelta\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_images_path = \"/Users/wajdiahmed/Kaggle/Single_Cut/images/\"\n",
    "train_segs_path = \"/Users/wajdiahmed/Kaggle/Single_Cut/masks/\"\n",
    "train_batch_size = 2\n",
    "n_classes = 2\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "validate = 'store_false'\n",
    "val_images=\"\"\n",
    "val_annotations=\"\"\n",
    "val_batch_size=2\n",
    "save_weights_path = '/'\n",
    "epochs = 5\n",
    "load_weights = \"\"\n",
    "\n",
    "optimizer_name = \"adam\"\n",
    "model_name = \"VGGUnet2\"\n",
    "\n",
    "if validate:\n",
    "    val_images_path = val_images\n",
    "    val_segs_path = val_annotations\n",
    "    val_batch_size = val_batch_size\n",
    "\n",
    "#modelFns = { 'vgg_segnet':Models.VGGSegnet.VGGSegnet , 'vgg_unet':Models.VGGUnet.VGGUnet , 'vgg_unet2':Models.VGGUnet.VGGUnet2 , 'fcn8':Models.FCN8.FCN8 , 'fcn32':Models.FCN32.FCN32   }\n",
    "#modelFN = modelFns[ model_name ]\n",
    "#modelFN = model_name\n",
    "\n",
    "m = VGGUnet2(n_classes, input_height=input_height ,input_width=input_width )\n",
    "m.compile(loss='categorical_crossentropy',\n",
    "      optimizer= optimizer_name ,\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "if len( load_weights ) > 0:\n",
    "    m.load_weights(load_weights)\n",
    "\n",
    "\n",
    "print (\"Model output shape\" ,  m.output_shape)\n",
    "\n",
    "output_height = m.outputHeight\n",
    "output_width = m.outputWidth\n",
    "\n",
    "G  = LoadBatches.imageSegmentationGenerator( train_images_path , train_segs_path ,  train_batch_size,  n_classes , input_height , input_width , output_height , output_width   )\n",
    "\n",
    "\n",
    "if validate:\n",
    "    G2  = LoadBatches.imageSegmentationGenerator( val_images_path , val_segs_path ,  val_batch_size,  n_classes , input_height , input_width , output_height , output_width   )\n",
    "\n",
    "if not validate:\n",
    "    for ep in range( epochs ):\n",
    "        m.fit_generator( G , 512  , epochs=1 )\n",
    "        m.save_weights( save_weights_path + \".\" + str( ep ) )\n",
    "        m.save( save_weights_path + \".model.\" + str( ep ) )\n",
    "else:\n",
    "    for ep in range( epochs ):\n",
    "        m.fit_generator( G , 512  , validation_data=G2 , validation_steps=200 ,  epochs=1 )\n",
    "        m.save_weights( save_weights_path + \".\" + str( ep )  )\n",
    "        m.save( save_weights_path + \".model.\" + str( ep ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
